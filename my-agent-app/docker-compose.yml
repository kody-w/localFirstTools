version: '3.8'

services:
  agent_function:
    build:
      context: ./azure_function_app
      dockerfile: Dockerfile
    ports:
      - "${FUNCTION_APP_PORT}:80"
    environment:
      AzureWebJobsStorage: ${AZURE_WEBJOBS_STORAGE}
      FUNCTIONS_WORKER_RUNTIME: python
      AZURE_OPENAI_API_KEY: ${AZURE_OPENAI_API_KEY}
      AZURE_OPENAI_API_VERSION: ${AZURE_OPENAI_API_VERSION}
      AZURE_OPENAI_ENDPOINT: ${AZURE_OPENAI_ENDPOINT}
      AZURE_OPENAI_DEPLOYMENT_NAME: ${AZURE_OPENAI_DEPLOYMENT_NAME}
      ASSISTANT_NAME: ${ASSISTANT_NAME}
      CHARACTERISTIC_DESCRIPTION: ${CHARACTERISTIC_DESCRIPTION}
      USE_OLLAMA: ${USE_OLLAMA}
      OLLAMA_API_BASE_URL: ${OLLAMA_API_BASE_URL}
      OLLAMA_MODEL_NAME: ${OLLAMA_MODEL_NAME}
      USE_AZURE_STORAGE: ${USE_AZURE_STORAGE}
      AZURE_FILES_SHARE_NAME: ${AZURE_FILES_SHARE_NAME}
      LOCAL_STORAGE_BASE_PATH: ${LOCAL_STORAGE_BASE_PATH}
    volumes:
      - ./local_data:/home/site/wwwroot/local_storage
    depends_on:
      - ollama
    networks:
      - agent_network

  ollama:
    image: ollama/ollama
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    command: >
      bash -c "
      ollama serve &
      echo 'Waiting for Ollama server to be ready...'
      while ! curl -s http://localhost:11434/api/tags > /dev/null; do sleep 1; done
      echo 'Ollama server ready. Pulling model...'
      ollama pull ${OLLAMA_MODEL_NAME} || echo 'Model pull failed or model already exists.'
      wait -n
      exit $?
      "
    networks:
      - agent_network

volumes:
  ollama_models:

networks:
  agent_network:
    driver: bridge
